[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog(x)",
    "section": "",
    "text": "Post With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nMar 27, 2025\n\n\nHarlow Malloc\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nMar 24, 2025\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index2.html",
    "href": "index2.html",
    "title": "Sonic Signs",
    "section": "",
    "text": "O mind, what are you thinking? Why do you waver or get agitated? You believe in little things (or small-minded concepts) even though sages like Sanaka and others have spoken of the truth… why do you still cling to the transient, O mind? Truly follow the devotee, and realise that the real source of strength is that divine energy. ~Dr. Balamuralikrishna Music transcends human psyche. Not everyone can sing, but everyone can feel emotions. The mark of a exceptional singer is to evocative the ubiquitous ‘Bhaav’ or emotion inside the heart. Bhartanatyam as a dance form is celebrated and revered throughout the world. It’s foundation is on discipline and structure wrapped with devotion as a act of surrendering tot he supreme deity. Art can never die, it lives on the heart of the patreons. In this project we delve into Neural Networks, CNNs and error propagation. Keeping the technicals asides we are transforming the notion of classical and technological by bridging the gap with cybernetics and creative coding. The project creates an elegant outcome at the intersection of Bhartanatyam and contemporary machine learning technologies. The creative outcome of our inquiry is an interactive mudra detector that detects mudras in real time and plays a musical note linked to the same. Bharatanatyam is full of symbolism, with every mudra holding multiple layers of narrative, spiritual, and emotional meaning. This project aims to document and reinterpret these gestures in the framework of artificial intelligence, not to supplant the meaning but to create new pathways of interactive storytelling. By providing technology with the ability to hear and reply to these ancient movements, the project presents a dynamic archive and performing space that is both informative and creative. By uniting code and culture, and gesture and generative response, this project transcends being a tool, it becomes a extant interface between the past and present. It is an offering from algorithms’ precision to Bharatanatyam’s flowing grace, from silicon’s silence to the timbre of sound.\nWhat is left is a reminder that technology, applied with discretion, can be not a disruptor of tradition but its humble interpreter. This mudra detector is a little more than technological design, but an homage, a rhythmically encoded paean to the expressive intelligence of the human body, the heart of music, and the timeless beauty of classical art.\n\n\n\n\n\n\n\n\n\nThe main objective of this project is to develop a gesture recognition system that is able to:\n-Recognize major Bharatanatyam mudras via a webcam with the help of AI.\n-React to every mudra with corresponding visual and audio components that mirror or enhance its meaning or emotional content.\n\n\n\n\n\n\n-Data Collection: A labeled dataset of Bharatanatyam mudra samples is generated with the webcam and the handpose model of ml5.js. A mudra is captured through each of the 21 keypoints of the hand.\n-Model Training: A neural network is trained custom with ml5.neuralNetwork to classify the gesture according to these keypoints.\n-Real-Time Interaction: The trained model is incorporated into a p5.js sketch that does real-time classification off webcam input.\nEmbodied Feedback System: -A recognized mudra invokes: -A distinctive sound (conventional instruments such as veena, flute, mridangam) -A generative image (e.g., mandala designs, color waves, Sanskrit words) -Optionally, physical lights with Arduino and RGB LEDs —\nTools and Techniques p5.js, ml5.js, handpose model Custom sound samples and visual animations GitHub Pages or Glitch for online hosting —\nExpected Outcomes: -A working web-based demo that recognizes and reacts to 4–6 distinct Bharatanatyam mudras. -A performative presentation showcasing the system in use — where mudras trigger audio-visual feedback. -An online archive/interface that introduces users to mudras, their meanings, and their recognition through AI."
  },
  {
    "objectID": "index2.html#objective",
    "href": "index2.html#objective",
    "title": "Sonic Signs",
    "section": "",
    "text": "The main objective of this project is to develop a gesture recognition system that is able to:\n-Recognize major Bharatanatyam mudras via a webcam with the help of AI.\n-React to every mudra with corresponding visual and audio components that mirror or enhance its meaning or emotional content."
  },
  {
    "objectID": "index2.html#methodology",
    "href": "index2.html#methodology",
    "title": "Sonic Signs",
    "section": "",
    "text": "-Data Collection: A labeled dataset of Bharatanatyam mudra samples is generated with the webcam and the handpose model of ml5.js. A mudra is captured through each of the 21 keypoints of the hand.\n-Model Training: A neural network is trained custom with ml5.neuralNetwork to classify the gesture according to these keypoints.\n-Real-Time Interaction: The trained model is incorporated into a p5.js sketch that does real-time classification off webcam input.\nEmbodied Feedback System: -A recognized mudra invokes: -A distinctive sound (conventional instruments such as veena, flute, mridangam) -A generative image (e.g., mandala designs, color waves, Sanskrit words) -Optionally, physical lights with Arduino and RGB LEDs —\nTools and Techniques p5.js, ml5.js, handpose model Custom sound samples and visual animations GitHub Pages or Glitch for online hosting —\nExpected Outcomes: -A working web-based demo that recognizes and reacts to 4–6 distinct Bharatanatyam mudras. -A performative presentation showcasing the system in use — where mudras trigger audio-visual feedback. -An online archive/interface that introduces users to mudras, their meanings, and their recognition through AI."
  }
]